{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "quLYd8Pfj0AH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KHOI TUAN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os # Thêm thư viện os để kiểm tra file\n",
        "\n",
        "# %% [markdown]\n",
        "# Tải dữ liệu từ file CSV.\n",
        "# Hãy đảm bảo file `data.xlsx - Sheet1.csv` nằm trong cùng thư mục với notebook này, hoặc cung cấp đường dẫn đầy đủ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtb8-o3tmxn-",
        "outputId": "2991fc27-c4e5-4d08-f7e9-bb9b23090a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã tải thành công file '/content/drive/MyDrive/dataset/datacsv.csv' với dấu phẩy phân cách.\n",
            "\n",
            "--- Thông tin ban đầu của dữ liệu ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10463 entries, 0 to 10462\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   ID           10463 non-null  int64  \n",
            " 1   Timestamp    10463 non-null  object \n",
            " 2   humidity     10463 non-null  float64\n",
            " 3   temperature  10463 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(1)\n",
            "memory usage: 327.1+ KB\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "file_path = \"/content/drive/MyDrive/dataset/datacsv.csv\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Lỗi: Không tìm thấy file '{file_path}'. Vui lòng kiểm tra lại đường dẫn.\")\n",
        "    # exit() # Trong notebook, bạn có thể không muốn thoát kernel ngay\n",
        "else:\n",
        "    try:\n",
        "        # Thử đọc với dấu phẩy làm dấu phân cách\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Đã tải thành công file '{file_path}' với dấu phẩy phân cách.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi đọc file CSV bằng dấu phẩy: {e}\")\n",
        "        try:\n",
        "            # Thử đọc với dấu chấm phẩy làm dấu phân cách\n",
        "            df = pd.read_csv(file_path, delimiter=';')\n",
        "            print(f\"Đã tải thành công file '{file_path}' với dấu chấm phẩy phân cách.\")\n",
        "        except Exception as e_delim:\n",
        "            print(f\"Vẫn lỗi khi đọc file CSV với dấu phân cách khác: {e_delim}\")\n",
        "            df = None # Gán df là None nếu không đọc được file\n",
        "\n",
        "if df is not None:\n",
        "    print(\"\\n--- Thông tin ban đầu của dữ liệu ---\")\n",
        "    df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGkBLFnv_XfR"
      },
      "outputs": [],
      "source": [
        "# # Giả sử df là DataFrame chứa toàn bộ dữ liệu của bạn\n",
        "# # Và bạn đã xác định được temp_col_name và humi_col_name\n",
        "\n",
        "# # Ví dụ: Chia dữ liệu (bạn có thể dùng train_test_split của scikit-learn)\n",
        "# train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42) # 70% train\n",
        "# val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42) # 15% val, 15% test\n",
        "# CHÚ Ý: Với dữ liệu chuỗi thời gian, việc chia ngẫu nhiên có thể không phù hợp,\n",
        "# bạn có thể cần chia theo thứ tự thời gian.\n",
        "\n",
        "# Giả sử train_df là DataFrame chứa dữ liệu huấn luyện của bạn\n",
        "# scaler_temp = MinMaxScaler(feature_range=(0, 1))\n",
        "# scaler_humi = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Fit scaler CHỈ trên dữ liệu huấn luyện\n",
        "# Dữ liệu cần có dạng cột (N_samples, 1)\n",
        "# scaler_temp.fit(train_df[[temp_col_name]].astype(float))\n",
        "# scaler_humi.fit(train_df[[humi_col_name]].astype(float))\n",
        "\n",
        "# print(\"Đã fit scaler_temp và scaler_humi trên dữ liệu huấn luyện.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRneDuu-ntTj"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 2: Kiểm tra dữ liệu ban đầu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjdvzjM4nuYN",
        "outputId": "1868ba1c-feab-4313-ee9a-794e38b454a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 5 dòng dữ liệu đầu tiên ---\n",
            "   ID            Timestamp   humidity  temperature\n",
            "0   1  2025-05-14 16:18:56  56.568050    27.420235\n",
            "1   2  2025-05-14 16:19:06  57.285023    27.423477\n",
            "2   3  2025-05-14 16:19:16  57.293415    27.423668\n",
            "3   4  2025-05-14 16:19:26  57.070732    27.427673\n",
            "4   5  2025-05-14 16:21:03  57.070732    27.427673\n",
            "\n",
            "--- 5 dòng dữ liệu cuối cùng ---\n",
            "          ID            Timestamp   humidity  temperature\n",
            "10458  10459  2025-05-19 05:04:12  74.792770    31.539536\n",
            "10459  10460  2025-05-19 05:04:22  74.007889    31.541824\n",
            "10460  10461  2025-05-19 05:04:32  73.658180    31.557846\n",
            "10461  10462  2025-05-19 05:04:42  73.520851    31.565666\n",
            "10462  10463  2025-05-19 05:04:52  73.128128    31.559181\n",
            "\n",
            "--- Thống kê mô tả ---\n",
            "                  ID            Timestamp      humidity   temperature\n",
            "count   10463.000000                10463  10463.000000  10463.000000\n",
            "unique           NaN                10463           NaN           NaN\n",
            "top              NaN  2025-05-19 05:04:52           NaN           NaN\n",
            "freq             NaN                    1           NaN           NaN\n",
            "mean     5232.000000                  NaN     68.538550     31.456528\n",
            "std      3020.552267                  NaN      3.486180      1.001393\n",
            "min         1.000000                  NaN     51.757050     25.997925\n",
            "25%      2616.500000                  NaN     66.203880     30.934048\n",
            "50%      5232.000000                  NaN     69.566254     31.540489\n",
            "75%      7847.500000                  NaN     70.823574     32.199287\n",
            "max     10463.000000                  NaN     85.678574     32.674217\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "if df is not None:\n",
        "    print(\"\\n--- 5 dòng dữ liệu đầu tiên ---\")\n",
        "    print(df.head())\n",
        "    print(\"\\n--- 5 dòng dữ liệu cuối cùng ---\")\n",
        "    print(df.tail())\n",
        "    print(\"\\n--- Thống kê mô tả ---\")\n",
        "    print(df.describe(include='all')) # include='all' để xem cả các cột không phải số\n",
        "else:\n",
        "    print(\"DataFrame chưa được tải. Vui lòng kiểm tra lỗi ở bước tải dữ liệu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw9EuPOXn_lG"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 3: Xác định các cột quan trọng\n",
        "#\n",
        "# Dựa vào kết quả `df.info()` và `df.head()` ở trên, hãy xác định chính xác tên các cột chứa Timestamp, Temperature, và Humidity trong file của bạn.\n",
        "#\n",
        "# **Quan trọng:** Chỉnh sửa các biến `timestamp_col_name`, `temperature_col_name`, `humidity_col_name` dưới đây cho phù hợp với tên cột thực tế trong file CSV của bạn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx9i-S_XoAyu",
        "outputId": "5c494d1a-3318-4226-eaa1-c2ce9e61bec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Các cột được xác định (vui lòng kiểm tra lại!) ---\n",
            "Cột Timestamp: Timestamp\n",
            "Cột Temperature: temperature\n",
            "Cột Humidity: humidity\n",
            "\n",
            "--- Dữ liệu đã chọn và đổi tên cột ---\n",
            "             Timestamp  Temperature   Humidity\n",
            "0  2025-05-14 16:18:56    27.420235  56.568050\n",
            "1  2025-05-14 16:19:06    27.423477  57.285023\n",
            "2  2025-05-14 16:19:16    27.423668  57.293415\n",
            "3  2025-05-14 16:19:26    27.427673  57.070732\n",
            "4  2025-05-14 16:21:03    27.427673  57.070732\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "if df is not None:\n",
        "    # --- Người dùng cần CẬP NHẬT tên cột thực tế tại đây ---\n",
        "    timestamp_col_name = 'Timestamp' # Ví dụ: 'ThoiGian', 'Timestamp', 'Date Time'\n",
        "    temperature_col_name = 'temperature' # Ví dụ: 'NhietDo', 'Temp (C)', 'Temperature'\n",
        "    humidity_col_name = 'humidity' # Ví dụ: 'DoAm', 'Humid (%)', 'Humidity'\n",
        "    # --- Kết thúc phần người dùng cần cập nhật ---\n",
        "\n",
        "    # Cố gắng tự động phát hiện (heuristic)\n",
        "    potential_cols = list(df.columns)\n",
        "    for col in potential_cols:\n",
        "        col_lower = str(col).lower() # Đảm bảo col là string trước khi lower()\n",
        "        if not timestamp_col_name and ('time' in col_lower or 'date' in col_lower or 'ngày' in col_lower or 'thời gian' in col_lower):\n",
        "            timestamp_col_name = col\n",
        "        elif not temperature_col_name and ('temp' in col_lower or 'nhiet' in col_lower or 'nhiệt' in col_lower):\n",
        "            temperature_col_name = col\n",
        "        elif not humidity_col_name and ('humid' in col_lower or 'ẩm' in col_lower or 'am' in col_lower):\n",
        "            humidity_col_name = col\n",
        "\n",
        "    # Nếu không tự động tìm được, yêu cầu người dùng nhập\n",
        "    if not timestamp_col_name:\n",
        "        print(\"Không tự động tìm thấy cột Timestamp. Vui lòng nhập tên cột chính xác.\")\n",
        "        # timestamp_col_name = input(\"Nhập tên cột Timestamp: \") # Hoặc gán thủ công\n",
        "    if not temperature_col_name:\n",
        "        print(\"Không tự động tìm thấy cột Temperature. Vui lòng nhập tên cột chính xác.\")\n",
        "        # temperature_col_name = input(\"Nhập tên cột Temperature: \") # Hoặc gán thủ công\n",
        "    if not humidity_col_name:\n",
        "        print(\"Không tự động tìm thấy cột Humidity. Vui lòng nhập tên cột chính xác.\")\n",
        "        # humidity_col_name = input(\"Nhập tên cột Humidity: \") # Hoặc gán thủ công\n",
        "\n",
        "    print(f\"\\n--- Các cột được xác định (vui lòng kiểm tra lại!) ---\")\n",
        "    print(f\"Cột Timestamp: {timestamp_col_name}\")\n",
        "    print(f\"Cột Temperature: {temperature_col_name}\")\n",
        "    print(f\"Cột Humidity: {humidity_col_name}\")\n",
        "\n",
        "    # Kiểm tra xem các cột đã được xác định chưa\n",
        "    if not all([timestamp_col_name, temperature_col_name, humidity_col_name]):\n",
        "        print(\"\\nLỖI: Một hoặc nhiều tên cột quan trọng (Timestamp, Temperature, Humidity) chưa được xác định chính xác.\")\n",
        "        print(\"Vui lòng cập nhật các biến `timestamp_col_name`, `temperature_col_name`, `humidity_col_name` trong ô code phía trên.\")\n",
        "        df_selected = None\n",
        "    elif not all(col in df.columns for col in [timestamp_col_name, temperature_col_name, humidity_col_name]):\n",
        "        print(\"\\nLỖI: Một hoặc nhiều tên cột đã xác định không tồn tại trong DataFrame.\")\n",
        "        print(f\"Các cột trong DataFrame: {df.columns.tolist()}\")\n",
        "        print(f\"Cột đã xác định: Timestamp='{timestamp_col_name}', Temperature='{temperature_col_name}', Humidity='{humidity_col_name}'\")\n",
        "        df_selected = None\n",
        "    else:\n",
        "        df_selected = df[[timestamp_col_name, temperature_col_name, humidity_col_name]].copy()\n",
        "        df_selected.rename(columns={\n",
        "            timestamp_col_name: 'Timestamp',\n",
        "            temperature_col_name: 'Temperature',\n",
        "            humidity_col_name: 'Humidity'\n",
        "        }, inplace=True)\n",
        "        print(\"\\n--- Dữ liệu đã chọn và đổi tên cột ---\")\n",
        "        print(df_selected.head())\n",
        "else:\n",
        "    df_selected = None\n",
        "    print(\"DataFrame chưa được tải.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBzkkujuomYf"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 4: Xử lý cột Timestamp\n",
        "# Chuyển đổi cột 'Timestamp' sang kiểu `datetime`, sắp xếp và đặt làm index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lrl9lVcom7L",
        "outputId": "6c9608d9-4eb6-4cab-9a73-7bb57be7c0da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chuyển đổi Timestamp thành công (thử trực tiếp).\n",
            "\n",
            "--- Dữ liệu sau khi xử lý Timestamp ---\n",
            "                     Temperature   Humidity\n",
            "Timestamp                                  \n",
            "2025-05-14 16:18:56    27.420235  56.568050\n",
            "2025-05-14 16:19:06    27.423477  57.285023\n",
            "2025-05-14 16:19:16    27.423668  57.293415\n",
            "2025-05-14 16:19:26    27.427673  57.070732\n",
            "2025-05-14 16:21:03    27.427673  57.070732\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 10463 entries, 2025-05-14 16:18:56 to 2025-05-19 05:04:52\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Temperature  10463 non-null  float64\n",
            " 1   Humidity     10463 non-null  float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 245.2 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "if df_selected is not None:\n",
        "    try:\n",
        "        # Cố gắng chuyển đổi trực tiếp\n",
        "        df_selected['Timestamp'] = pd.to_datetime(df_selected['Timestamp'])\n",
        "        print(\"Chuyển đổi Timestamp thành công (thử trực tiếp).\")\n",
        "    except Exception as e_direct:\n",
        "        print(f\"Lỗi khi chuyển đổi Timestamp trực tiếp: {e_direct}\")\n",
        "        try:\n",
        "            # Thử với dayfirst=True (ví dụ: dd/mm/yyyy)\n",
        "            df_selected['Timestamp'] = pd.to_datetime(df_selected['Timestamp'], dayfirst=True)\n",
        "            print(\"Chuyển đổi Timestamp thành công (thử với dayfirst=True).\")\n",
        "        except Exception as e_dayfirst:\n",
        "            print(f\"Lỗi khi chuyển đổi Timestamp với dayfirst=True: {e_dayfirst}\")\n",
        "            try:\n",
        "                # Thử với một số định dạng phổ biến khác (bạn có thể cần thêm định dạng của mình)\n",
        "                # Ví dụ: '%Y-%m-%d %H:%M:%S', '%m/%d/%Y %I:%M:%S %p'\n",
        "                df_selected['Timestamp'] = pd.to_datetime(df_selected['Timestamp'], format='%d/%m/%Y %H:%M') # CẬP NHẬT ĐỊNH DẠNG NẾU CẦN\n",
        "                print(\"Chuyển đổi Timestamp thành công (thử với định dạng cụ thể, ví dụ: %d/%m/%Y %H:%M).\")\n",
        "            except Exception as e_format:\n",
        "                print(f\"LỖI NGHIÊM TRỌNG: Không thể chuyển đổi cột Timestamp sang datetime: {e_format}\")\n",
        "                print(\"Vui lòng kiểm tra định dạng của cột Timestamp trong file CSV và cập nhật `format` trong `pd.to_datetime()` nếu cần.\")\n",
        "                df_selected = None # Đánh dấu là lỗi để các bước sau không chạy\n",
        "\n",
        "if df_selected is not None:\n",
        "    df_selected.sort_values('Timestamp', inplace=True)\n",
        "    df_selected.set_index('Timestamp', inplace=True)\n",
        "    print(\"\\n--- Dữ liệu sau khi xử lý Timestamp ---\")\n",
        "    print(df_selected.head())\n",
        "    print(df_selected.info())\n",
        "else:\n",
        "    print(\"Không thể tiếp tục do lỗi xử lý Timestamp hoặc lựa chọn cột.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIbONXtMp1mB",
        "outputId": "9d2507c9-3c0e-4d1e-82f2-67aebfab74a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     Temperature   Humidity\n",
            "Timestamp                                  \n",
            "2025-05-14 16:18:56    27.420235  56.568050\n",
            "2025-05-14 16:19:06    27.423477  57.285023\n",
            "2025-05-14 16:19:16    27.423668  57.293415\n",
            "2025-05-14 16:19:26    27.427673  57.070732\n",
            "2025-05-14 16:21:03    27.427673  57.070732\n",
            "...                          ...        ...\n",
            "2025-05-19 05:04:12    31.539536  74.792770\n",
            "2025-05-19 05:04:22    31.541824  74.007889\n",
            "2025-05-19 05:04:32    31.557846  73.658180\n",
            "2025-05-19 05:04:42    31.565666  73.520851\n",
            "2025-05-19 05:04:52    31.559181  73.128128\n",
            "\n",
            "[10463 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELXFrTD6o0gI"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 5: Xử lý giá trị thiếu (Missing Values)\n",
        "# Sử dụng phương pháp `ffill` (forward fill) và `bfill` (backward fill)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9vASSU-o17y",
        "outputId": "00d7fc42-06a0-45a4-b8a7-6a73994ba8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Xử lý giá trị thiếu ---\n",
            "Số giá trị thiếu trước khi xử lý:\n",
            " Temperature    0\n",
            "Humidity       0\n",
            "dtype: int64\n",
            "\n",
            "Số giá trị thiếu sau khi xử lý (ffill, bfill):\n",
            " Temperature    0\n",
            "Humidity       0\n",
            "dtype: int64\n",
            "                     Temperature   Humidity\n",
            "Timestamp                                  \n",
            "2025-05-14 16:18:56    27.420235  56.568050\n",
            "2025-05-14 16:19:06    27.423477  57.285023\n",
            "2025-05-14 16:19:16    27.423668  57.293415\n",
            "2025-05-14 16:19:26    27.427673  57.070732\n",
            "2025-05-14 16:21:03    27.427673  57.070732\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "if df_selected is not None:\n",
        "    # Chuyển đổi cột Temperature và Humidity sang kiểu số, lỗi sẽ thành NaN\n",
        "    df_selected['Temperature'] = pd.to_numeric(df_selected['Temperature'], errors='coerce')\n",
        "    df_selected['Humidity'] = pd.to_numeric(df_selected['Humidity'], errors='coerce')\n",
        "\n",
        "    missing_before = df_selected.isnull().sum()\n",
        "    df_selected.ffill(inplace=True)\n",
        "    df_selected.bfill(inplace=True) # Để xử lý NaN ở đầu nếu có\n",
        "    missing_after = df_selected.isnull().sum()\n",
        "\n",
        "    print(\"\\n--- Xử lý giá trị thiếu ---\")\n",
        "    print(\"Số giá trị thiếu trước khi xử lý:\\n\", missing_before)\n",
        "    print(\"\\nSố giá trị thiếu sau khi xử lý (ffill, bfill):\\n\", missing_after)\n",
        "\n",
        "    if df_selected.isnull().sum().any():\n",
        "        print(\"\\nCẢNH BÁO: Vẫn còn giá trị thiếu sau khi ffill/bfill. Có thể do toàn bộ cột bị thiếu hoặc dữ liệu không đủ.\")\n",
        "        print(\"Xem xét các phương pháp xử lý khác hoặc kiểm tra lại dữ liệu gốc.\")\n",
        "    print(df_selected.head())\n",
        "else:\n",
        "    print(\"Không thể tiếp tục do lỗi ở các bước trước.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H286Ux1Lo6F8"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 6: Kiểm tra tần suất dữ liệu và Resample (Lấy mẫu lại)\n",
        "#\n",
        "# Mô hình yêu cầu đầu vào là dữ liệu mỗi 10 giây. Chúng ta sẽ resample dữ liệu về tần suất này.\n",
        "# Đầu ra của mô hình là mỗi 15 phút."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F75V4YSBpFg8",
        "outputId": "572613ea-0718-4600-9a15-a7738c491aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Thống kê khoảng cách thời gian giữa các mẫu (trước resample) ---\n",
            "count                        10462\n",
            "mean     0 days 00:00:37.426495889\n",
            "std      0 days 00:39:45.611835314\n",
            "min                0 days 00:00:03\n",
            "25%                0 days 00:00:10\n",
            "50%                0 days 00:00:10\n",
            "75%                0 days 00:00:10\n",
            "max                2 days 18:35:59\n",
            "Name: Timestamp, dtype: object\n",
            "Khoảng cách thời gian phổ biến (median) trước resample: 10.0 giây\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "if df_selected is not None and not df_selected.isnull().sum().any():\n",
        "    time_diffs = df_selected.index.to_series().diff().dropna()\n",
        "    print(\"\\n--- Thống kê khoảng cách thời gian giữa các mẫu (trước resample) ---\")\n",
        "    if not time_diffs.empty:\n",
        "        print(time_diffs.describe())\n",
        "        median_freq_seconds = time_diffs.median().total_seconds()\n",
        "        print(f\"Khoảng cách thời gian phổ biến (median) trước resample: {median_freq_seconds} giây\")\n",
        "    else:\n",
        "        print(\"Không đủ dữ liệu để tính khoảng cách thời gian (chỉ có 1 dòng hoặc không có).\")\n",
        "\n",
        "    # Resample về tần suất 10 giây, điền giá trị thiếu bằng ffill rồi bfill\n",
        "    # Điều này rất quan trọng và phụ thuộc vào bản chất dữ liệu gốc của bạn.\n",
        "    # Nếu dữ liệu gốc thưa (ví dụ: mỗi giờ), việc resample xuống 10s có thể không mang lại thông tin thực.\n",
        "#     print(\"\\n--- Resampling dữ liệu về tần suất 10 giây ---\")\n",
        "#     try:\n",
        "#         df_resampled = df_selected.resample('10S').ffill().bfill()\n",
        "#         print(\"Dữ liệu đã được resample/điền đầy về tần suất 10 giây.\")\n",
        "#         print(df_resampled.head())\n",
        "#         print(df_resampled.info())\n",
        "#     except Exception as e:\n",
        "#         print(f\"Lỗi khi resampling: {e}. Cân nhắc kiểm tra dữ liệu index.\")\n",
        "#         df_resampled = None # Đánh dấu lỗi\n",
        "# else:\n",
        "#     df_resampled = None\n",
        "#     print(\"Không thể tiếp tục do lỗi ở các bước trước hoặc còn giá trị thiếu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfobbCBxrTEz"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 7: Chuẩn hóa dữ liệu (Scaling)\n",
        "# Chuẩn hóa giá trị Nhiệt độ và Độ ẩm về khoảng (0, 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOg_pMC_rbVc",
        "outputId": "ee3f52e1-a537-462c-8339-b2d6b64db7a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Dữ liệu sau khi chuẩn hóa ---\n",
            "                     Temperature   Humidity  Temperature_scaled  \\\n",
            "Timestamp                                                         \n",
            "2025-05-14 16:18:56    27.420235  56.568050            0.213039   \n",
            "2025-05-14 16:19:06    27.423477  57.285023            0.213525   \n",
            "2025-05-14 16:19:16    27.423668  57.293415            0.213553   \n",
            "2025-05-14 16:19:26    27.427673  57.070732            0.214153   \n",
            "2025-05-14 16:21:03    27.427673  57.070732            0.214153   \n",
            "\n",
            "                     Humidity_scaled  \n",
            "Timestamp                             \n",
            "2025-05-14 16:18:56         0.141827  \n",
            "2025-05-14 16:19:06         0.162964  \n",
            "2025-05-14 16:19:16         0.163211  \n",
            "2025-05-14 16:19:26         0.156646  \n",
            "2025-05-14 16:21:03         0.156646  \n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "df_resampled = df_selected\n",
        "if df_resampled is not None:\n",
        "    scaler_temp = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaler_hum = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "    # Đảm bảo cột là số trước khi scale\n",
        "    df_resampled['Temperature'] = pd.to_numeric(df_resampled['Temperature'], errors='coerce')\n",
        "    df_resampled['Humidity'] = pd.to_numeric(df_resampled['Humidity'], errors='coerce')\n",
        "\n",
        "    # Kiểm tra lại NaN sau to_numeric (nếu có lỗi chuyển đổi)\n",
        "    if df_resampled[['Temperature', 'Humidity']].isnull().sum().any():\n",
        "        print(\"CẢNH BÁO: Có giá trị NaN trong cột Temperature/Humidity sau khi ép kiểu số. Xử lý lại...\")\n",
        "        df_resampled.ffill(inplace=True).bfill(inplace=True) # Thử fill lại\n",
        "\n",
        "    if not df_resampled[['Temperature', 'Humidity']].isnull().sum().any():\n",
        "        df_resampled['Temperature_scaled'] = scaler_temp.fit_transform(df_resampled[['Temperature']])\n",
        "        df_resampled['Humidity_scaled'] = scaler_hum.fit_transform(df_resampled[['Humidity']])\n",
        "        print(\"\\n--- Dữ liệu sau khi chuẩn hóa ---\")\n",
        "        print(df_resampled.head())\n",
        "    else:\n",
        "        print(\"LỖI: Vẫn còn NaN trong Temperature/Humidity trước khi scaling. Không thể tiếp tục.\")\n",
        "        df_resampled = None # Đánh dấu lỗi\n",
        "else:\n",
        "    print(\"Không thể tiếp tục do lỗi ở bước resample.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "AVEcmrJnAo7I",
        "outputId": "cedbb231-44c9-4d6b-cbaa-366138961008"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-648983bcc39c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mscaler_humi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mscaler_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_for_scaler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mscaler_humi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_for_scaler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'humidity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Scalers fitted for this session using columns: 'temperature' and 'humidity'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                         \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                     )\n\u001b[0;32m-> 1093\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kind\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"USV\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead."
          ]
        }
      ],
      "source": [
        "# --- SCALER HANDLING ---\n",
        "        # QUAN TRỌNG: Đoạn này fit scaler từ CSV mỗi lần chạy.\n",
        "        # Trong sản xuất, bạn NÊN fit scalers một lần trên tập training,\n",
        "        # lưu chúng (ví dụ dùng joblib), và tải chúng lên ở đây.\n",
        "        # print(f\"\\nFitting scalers using data from '{file_path}' (NOTE: Ideally, load pre-fitted scalers).\")\n",
        "df_for_scaler = pd.read_csv(file_path)\n",
        "\n",
        "if 'temperature' not in df_for_scaler.columns or 'humidity' not in df_for_scaler.columns:\n",
        "    print(f\"FATAL: One or both columns ('temperature', 'humidity') not found in CSV for scaler fitting: {df_for_scaler.columns.tolist()}\")\n",
        "\n",
        "scaler_temp = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler_humi = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "scaler_temp.fit(df_for_scaler['temperature'].astype(float))\n",
        "scaler_humi.fit(df_for_scaler['humidity'].astype(float))\n",
        "print(f\"Scalers fitted for this session using columns: 'temperature' and 'humidity'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "q27MmSUW_5wz",
        "outputId": "d425f637-26ef-4131-94e4-1713227e21b6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'scaler_humi' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1b72be4e7cc3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler_output_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scaler_temp_trained.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler_humi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler_output_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scaler_humi_trained.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Đã lưu các scalers đã fit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'scaler_humi' is not defined"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "scaler_output_dir = \"/content/drive/MyDrive/IOT_saved_model/scalers\" # Ví dụ đường dẫn\n",
        "if not os.path.exists(scaler_output_dir):\n",
        "    os.makedirs(scaler_output_dir)\n",
        "\n",
        "joblib.dump(scaler_temp, os.path.join(scaler_output_dir, 'scaler_temp_trained.joblib'))\n",
        "joblib.dump(scaler_humi, os.path.join(scaler_output_dir, 'scaler_humi_trained.joblib'))\n",
        "print(\"Đã lưu các scalers đã fit.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2vDV58lrpJy"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 8: Tạo chuỗi Đầu vào (X) và Đầu ra (y) (ĐÃ CẬP NHẬT)\n",
        "#\n",
        "# * **Đầu vào (X)**: Dữ liệu 2 phút (12 điểm @ 10 giây/điểm) => 12 điểm dữ liệu (Nhiệt độ, Độ ẩm).\n",
        "# * **Đầu ra (y)**: Dữ liệu 24 giờ tiếp theo, lấy mẫu mỗi 15 phút => (24 * 60) / 15 = 96 điểm dữ liệu (Nhiệt độ, Độ ẩm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BjBzoj6rqHU",
        "outputId": "586ea75f-77d8-4571-92b2-a21b2b92ef94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bắt đầu tạo chuỗi X và y (ĐÃ CẬP NHẬT)...\n",
            "Số mẫu đầu vào (X) mỗi chuỗi: 12 (trên 2 phút, mỗi 10 giây)\n",
            "Số mẫu đầu ra (y) mỗi chuỗi: 96 (trên 24 giờ, mỗi 15 phút)\n",
            "Tổng số điểm dữ liệu sau resample (10s): 10463\n",
            "Đã xử lý 5000/10463 điểm bắt đầu tiềm năng cho X. Số cặp (X,y) đã tạo: 603\n",
            "Đã xử lý 10000/10463 điểm bắt đầu tiềm năng cho X. Số cặp (X,y) đã tạo: 603\n",
            "\n",
            "--- Hoàn thành tạo chuỗi X, y (ĐÃ CẬP NHẬT) ---\n",
            "Hình dạng của X: (603, 12, 2)\n",
            "Hình dạng của y: (603, 96, 2)\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "if df_resampled is not None and 'Temperature_scaled' in df_resampled.columns:\n",
        "    # --- THAY ĐỔI THAM SỐ ĐẦU VÀO ---\n",
        "    num_input_timesteps = 12  # 12 điểm dữ liệu đầu vào\n",
        "    input_sample_interval_seconds = 10 # Giữ nguyên tần suất resample cho đầu vào\n",
        "    input_window_duration_seconds = num_input_timesteps * input_sample_interval_seconds # 12 * 10s = 120s = 2 phút\n",
        "\n",
        "    # --- THAY ĐỔI THAM SỐ ĐẦU RA ---\n",
        "    output_window_duration_hours = 24 # 24 giờ dự đoán\n",
        "    output_sample_interval_minutes = 15 # Khoảng cách 15 phút cho mỗi điểm dự đoán\n",
        "    # Số điểm dữ liệu trong 24 giờ / khoảng cách lấy mẫu (15 phút)\n",
        "    num_output_timesteps = (output_window_duration_hours * 60) // output_sample_interval_minutes # (24*60)/15 = 96\n",
        "\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "\n",
        "    data_np = df_resampled[['Temperature_scaled', 'Humidity_scaled']].values\n",
        "    timestamps_np = df_resampled.index\n",
        "\n",
        "    print(f\"\\nBắt đầu tạo chuỗi X và y (ĐÃ CẬP NHẬT)...\")\n",
        "    print(f\"Số mẫu đầu vào (X) mỗi chuỗi: {num_input_timesteps} (trên {input_window_duration_seconds // 60} phút, mỗi {input_sample_interval_seconds} giây)\")\n",
        "    print(f\"Số mẫu đầu ra (y) mỗi chuỗi: {num_output_timesteps} (trên {output_window_duration_hours} giờ, mỗi {output_sample_interval_minutes} phút)\")\n",
        "    print(f\"Tổng số điểm dữ liệu sau resample (10s): {len(data_np)}\")\n",
        "\n",
        "    # Số điểm 10s trong một khoảng thời gian của Y (15 phút)\n",
        "    steps_per_output_interval = (output_sample_interval_minutes * 60) // input_sample_interval_seconds # (15 * 60) / 10 = 90\n",
        "\n",
        "    for i in range(len(data_np)):\n",
        "        # Xác định điểm kết thúc của chuỗi X\n",
        "        end_idx_x = i + num_input_timesteps\n",
        "        if end_idx_x > len(data_np): # Không đủ dữ liệu cho X\n",
        "            break\n",
        "\n",
        "        current_x_sequence = data_np[i : end_idx_x]\n",
        "\n",
        "        # Xác định thời điểm bắt đầu của chuỗi Y (ngay sau khi chuỗi X kết thúc)\n",
        "        timestamp_start_x = timestamps_np[i]\n",
        "        # Thời điểm bắt đầu Y là thời điểm ngay sau điểm cuối cùng của X\n",
        "        # Nếu X có num_input_timesteps điểm, mỗi điểm cách nhau input_sample_interval_seconds\n",
        "        # thì Y sẽ bắt đầu sau (num_input_timesteps * input_sample_interval_seconds) kể từ lúc X bắt đầu\n",
        "        timestamp_start_y_target = timestamp_start_x + pd.Timedelta(seconds=input_window_duration_seconds)\n",
        "\n",
        "        current_y_sequence_points = []\n",
        "        possible_y_sequence = True\n",
        "\n",
        "        # Tìm index trong timestamps_np cho thời điểm bắt đầu của Y\n",
        "        idx_actual_start_y = timestamps_np.searchsorted(timestamp_start_y_target)\n",
        "\n",
        "        if idx_actual_start_y >= len(timestamps_np) or \\\n",
        "           (timestamps_np[idx_actual_start_y] - timestamp_start_y_target).total_seconds() != 0 :\n",
        "            possible_y_sequence = False # Không tìm thấy điểm bắt đầu Y chính xác\n",
        "\n",
        "        if possible_y_sequence:\n",
        "            for k in range(num_output_timesteps): # 96 điểm cho Y\n",
        "                # Index của điểm y_k trong data_np (đã resample 10s)\n",
        "                # Mỗi điểm y cách nhau 15 phút = 90 mẫu 10 giây (steps_per_output_interval)\n",
        "                idx_yk = idx_actual_start_y + k * steps_per_output_interval\n",
        "\n",
        "                if idx_yk < len(data_np):\n",
        "                    current_y_sequence_points.append(data_np[idx_yk])\n",
        "                else:\n",
        "                    possible_y_sequence = False # Không đủ dữ liệu cho toàn bộ chuỗi Y\n",
        "                    break\n",
        "\n",
        "        if possible_y_sequence and len(current_y_sequence_points) == num_output_timesteps:\n",
        "            X_list.append(current_x_sequence)\n",
        "            y_list.append(np.array(current_y_sequence_points))\n",
        "\n",
        "        if (i + 1) % 5000 == 0:\n",
        "            print(f\"Đã xử lý {i+1}/{len(data_np)} điểm bắt đầu tiềm năng cho X. Số cặp (X,y) đã tạo: {len(X_list)}\")\n",
        "\n",
        "    if not X_list:\n",
        "        print(\"\\nLỖI: Không thể tạo được chuỗi X, y nào. Các lý do có thể:\")\n",
        "        print(\"1. Dữ liệu quá ngắn.\")\n",
        "        print(f\"   - Số điểm dữ liệu 10s sau resample: {len(data_np)}\")\n",
        "        # Tính toán sơ bộ số điểm 10s cần thiết\n",
        "        # Thời gian bao phủ bởi X: (num_input_timesteps - 1) * 10s\n",
        "        # Thời gian từ đầu X đến đầu Y: num_input_timesteps * 10s\n",
        "        # Thời gian bao phủ bởi Y: (num_output_timesteps - 1) * 15 phút\n",
        "        # Điểm cuối cùng của Y so với đầu X: (num_input_timesteps * 10s) + (num_output_timesteps - 1) * 15 phút\n",
        "        # Quy ra số lượng index 10s:\n",
        "        min_indices_needed = (num_input_timesteps -1) + \\\n",
        "                             1 + \\\n",
        "                             (num_output_timesteps -1) * steps_per_output_interval\n",
        "        print(f\"   - Ước tính số index 10s tối thiểu cần thiết để tạo 1 cặp (X,y) hoàn chỉnh: ~{min_indices_needed}\")\n",
        "\n",
        "        if len(data_np) < min_indices_needed:\n",
        "             print(f\"   ---> DỮ LIỆU CỦA BẠN (sau resample 10s) có {len(data_np)} điểm, CÓ VẺ QUÁ NGẮN.\")\n",
        "        print(\"2. Lỗi logic trong việc tìm kiếm điểm dữ liệu cho chuỗi Y (vấn đề timestamp alignment).\")\n",
        "        print(\"   Kiểm tra lại tần suất dữ liệu gốc và quá trình resample.\")\n",
        "        X_np = np.array([])\n",
        "        y_np = np.array([])\n",
        "    else:\n",
        "        X_np = np.array(X_list)\n",
        "        y_np = np.array(y_list)\n",
        "        print(f\"\\n--- Hoàn thành tạo chuỗi X, y (ĐÃ CẬP NHẬT) ---\")\n",
        "        print(f\"Hình dạng của X: {X_np.shape}\") # Mong đợi: (số_mẫu, 12, 2)\n",
        "        print(f\"Hình dạng của y: {y_np.shape}\") # Mong đợi: (số_mẫu, 96, 2)\n",
        "else:\n",
        "    print(\"Không thể tiếp tục tạo chuỗi X, y do lỗi ở các bước trước.\")\n",
        "    X_np = np.array([])\n",
        "    y_np = np.array([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sSiJE3MsKa-"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 9: (Placeholder) Xây dựng Mô hình LSTM (ĐÃ CẬP NHẬT CHO INPUT/OUTPUT MỚI)\n",
        "#\n",
        "# Phần này sẽ định nghĩa kiến trúc mô hình LSTM sử dụng TensorFlow/Keras.\n",
        "# Các thay đổi chính:\n",
        "# - `Input(shape=(12, số_features))`: Vì `num_input_timesteps` là 12.\n",
        "# - `RepeatVector(96)`: Vì `num_output_timesteps` là 96."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "nsoerKwlsM4m",
        "outputId": "7dc8016f-7a72-4aa4-ff6b-10b1ff59ed38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Cấu trúc Model (ĐÃ CẬP NHẬT) ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">67,072</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m67,072\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │           \u001b[38;5;34m258\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,914</span> (777.01 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m198,914\u001b[0m (777.01 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,914</span> (777.01 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m198,914\u001b[0m (777.01 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input\n",
        "\n",
        "if X_np.shape[0] > 0: # Chỉ xây dựng model nếu có dữ liệu\n",
        "    model = Sequential()\n",
        "    # --- CẬP NHẬT SHAPE ĐẦU VÀO ---\n",
        "    model.add(Input(shape=(num_input_timesteps, X_np.shape[2]))) # (12, 2)\n",
        "\n",
        "    # Encoder\n",
        "    model.add(LSTM(128, activation='relu', return_sequences=False))\n",
        "    # model.add(LSTM(64, activation='relu')) # Có thể thêm layer nếu muốn phức tạp hơn\n",
        "\n",
        "    # --- CẬP NHẬT SỐ LƯỢNG TIMESTEPS CHO DECODER ---\n",
        "    model.add(RepeatVector(num_output_timesteps)) # 96 timesteps cho output\n",
        "\n",
        "    # Decoder\n",
        "    model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "    # model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "\n",
        "    # TimeDistributed Dense layer để áp dụng một Dense layer cho mỗi timestep của output\n",
        "    model.add(TimeDistributed(Dense(y_np.shape[2]))) # y_np.shape[2] là số features output (2: Temp, Humid)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    print(\"\\n--- Cấu trúc Model (ĐÃ CẬP NHẬT) ---\")\n",
        "    model.summary()\n",
        "else:\n",
        "    print(\"Không có dữ liệu X, y để xây dựng model. Bỏ qua bước này.\")\n",
        "    model = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKEUlSBesh8P"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 10: (Placeholder) Chia dữ liệu và Huấn luyện Mô hình\n",
        "#\n",
        "# Chia dữ liệu thành tập huấn luyện (train), kiểm định (validation) và kiểm tra (test).\n",
        "# Sau đó huấn luyện mô hình."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmPi7M0Ns1Qb",
        "outputId": "9fe1a94d-0151-4701-8fc4-73d76edfec8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Kích thước các tập dữ liệu ---\n",
            "X_train shape: (422, 12, 2), y_train shape: (422, 96, 2)\n",
            "X_val shape: (90, 12, 2), y_val shape: (90, 96, 2)\n",
            "X_test shape: (91, 12, 2), y_test shape: (91, 96, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "if X_np.shape[0] > 0 and model is not None:\n",
        "    # Chia dữ liệu: 70% train, 15% validation, 15% test\n",
        "    # Với chuỗi thời gian, thường không xáo trộn (shuffle=False)\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_np, y_np, test_size=0.3, random_state=42, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, shuffle=False) # 0.5 * 0.3 = 0.15\n",
        "\n",
        "    print(f\"\\n--- Kích thước các tập dữ liệu ---\")\n",
        "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "    print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "else:\n",
        "    print(\"Không có dữ liệu hoặc model để huấn luyện. Bỏ qua bước này.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMO8_7NBw_Jf"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 10A: Chia dữ liệu và Lưu trữ các tập con ra file\n",
        "#\n",
        "# Thực hiện chia tách `X_np` và `y_np` thành các tập huấn luyện (train),\n",
        "# kiểm định (validation), và kiểm tra (test). Sau đó, lưu từng tập dữ liệu này\n",
        "# ra các file `.npy` riêng biệt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQMqrnvzw_sS",
        "outputId": "d1d6a494-d0dc-4c82-d4d5-6ca5a12695c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Kích thước các tập dữ liệu sau khi chia ---\n",
            "X_train shape: (422, 12, 2), y_train shape: (422, 96, 2)\n",
            "X_val shape: (90, 12, 2), y_val shape: (90, 96, 2)\n",
            "X_test shape: (91, 12, 2), y_test shape: (91, 96, 2)\n",
            "\n",
            "--- Bắt đầu lưu các tập dữ liệu ---\n",
            "Đã lưu X_train vào: /content/drive/MyDrive/dataset/data_splits/X_train.npy\n",
            "Đã lưu y_train vào: /content/drive/MyDrive/dataset/data_splits/y_train.npy\n",
            "Đã lưu X_val vào: /content/drive/MyDrive/dataset/data_splits/X_val.npy\n",
            "Đã lưu y_val vào: /content/drive/MyDrive/dataset/data_splits/y_val.npy\n",
            "Đã lưu X_test vào: /content/drive/MyDrive/dataset/data_splits/X_test.npy\n",
            "Đã lưu y_test vào: /content/drive/MyDrive/dataset/data_splits/y_test.npy\n",
            "\n",
            "--- Hoàn tất việc lưu dữ liệu! ---\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Kích thước các tập dữ liệu sau khi chia ---\")\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Tạo thư mục để lưu file nếu chưa có (ví dụ: 'data_splits')\n",
        "output_dir = \"/content/drive/MyDrive/dataset/data_splits\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "    print(f\"\\nĐã tạo thư mục: '{output_dir}'\")\n",
        "\n",
        "# Lưu các tập dữ liệu\n",
        "print(\"\\n--- Bắt đầu lưu các tập dữ liệu ---\")\n",
        "\n",
        "np.save(os.path.join(output_dir, 'X_train.npy'), X_train)\n",
        "print(f\"Đã lưu X_train vào: {os.path.join(output_dir, 'X_train.npy')}\")\n",
        "\n",
        "np.save(os.path.join(output_dir, 'y_train.npy'), y_train)\n",
        "print(f\"Đã lưu y_train vào: {os.path.join(output_dir, 'y_train.npy')}\")\n",
        "\n",
        "np.save(os.path.join(output_dir, 'X_val.npy'), X_val)\n",
        "print(f\"Đã lưu X_val vào: {os.path.join(output_dir, 'X_val.npy')}\")\n",
        "\n",
        "np.save(os.path.join(output_dir, 'y_val.npy'), y_val)\n",
        "print(f\"Đã lưu y_val vào: {os.path.join(output_dir, 'y_val.npy')}\")\n",
        "\n",
        "np.save(os.path.join(output_dir, 'X_test.npy'), X_test)\n",
        "print(f\"Đã lưu X_test vào: {os.path.join(output_dir, 'X_test.npy')}\")\n",
        "\n",
        "np.save(os.path.join(output_dir, 'y_test.npy'), y_test)\n",
        "print(f\"Đã lưu y_test vào: {os.path.join(output_dir, 'y_test.npy')}\")\n",
        "\n",
        "print(\"\\n--- Hoàn tất việc lưu dữ liệu! ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRMdp7NqxqRO",
        "outputId": "bcda25c6-8290-47fb-8910-2d989bd18c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã tải lại X_train_loaded shape: (422, 12, 2)\n",
            "Đã tải lại y_train_loaded shape: (422, 96, 2)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/dataset/data_splits\" # Đường dẫn đến thư mục chứa file\n",
        "\n",
        "X_train_loaded = np.load(os.path.join(output_dir, 'X_train.npy'))\n",
        "y_train_loaded = np.load(os.path.join(output_dir, 'y_train.npy'))\n",
        "X_val_loaded = np.load(os.path.join(output_dir, 'X_val.npy'))\n",
        "y_val_loaded = np.load(os.path.join(output_dir, 'y_val.npy'))\n",
        "X_test_loaded = np.load(os.path.join(output_dir, 'X_test.npy'))\n",
        "y_test_loaded = np.load(os.path.join(output_dir, 'y_test.npy'))\n",
        "\n",
        "print(\"Đã tải lại X_train_loaded shape:\", X_train_loaded.shape)\n",
        "print(\"Đã tải lại y_train_loaded shape:\", y_train_loaded.shape)\n",
        "# Tương tự cho các tập val và test..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M60aPk_ZtCbQ",
        "outputId": "878c9b42-17e4-44e9-8269-d6cc0fa2cbba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Bắt đầu huấn luyện Model ---\n",
            "Epoch 1/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 404ms/step - loss: 0.3382 - mae: 0.5342 - val_loss: 0.0228 - val_mae: 0.1169\n",
            "Epoch 2/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 339ms/step - loss: 0.0512 - mae: 0.1669 - val_loss: 0.0144 - val_mae: 0.0902\n",
            "Epoch 3/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 387ms/step - loss: 0.0277 - mae: 0.1215 - val_loss: 0.0139 - val_mae: 0.0880\n",
            "Epoch 4/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - loss: 0.0165 - mae: 0.0978 - val_loss: 0.0138 - val_mae: 0.0921\n",
            "Epoch 5/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 387ms/step - loss: 0.0142 - mae: 0.0918 - val_loss: 0.0122 - val_mae: 0.0861\n",
            "Epoch 6/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 244ms/step - loss: 0.0134 - mae: 0.0895 - val_loss: 0.0119 - val_mae: 0.0863\n",
            "Epoch 7/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 329ms/step - loss: 0.0126 - mae: 0.0869 - val_loss: 0.0108 - val_mae: 0.0821\n",
            "Epoch 8/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 243ms/step - loss: 0.0116 - mae: 0.0835 - val_loss: 0.0105 - val_mae: 0.0808\n",
            "Epoch 9/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - loss: 0.0109 - mae: 0.0818 - val_loss: 0.0099 - val_mae: 0.0777\n",
            "Epoch 10/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - loss: 0.0101 - mae: 0.0776 - val_loss: 0.0097 - val_mae: 0.0759\n",
            "Epoch 11/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 264ms/step - loss: 0.0089 - mae: 0.0723 - val_loss: 0.0080 - val_mae: 0.0690\n",
            "Epoch 12/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - loss: 0.0077 - mae: 0.0671 - val_loss: 0.0061 - val_mae: 0.0619\n",
            "Epoch 13/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - loss: 0.0055 - mae: 0.0550 - val_loss: 0.0086 - val_mae: 0.0759\n",
            "Epoch 14/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - loss: 0.0041 - mae: 0.0440 - val_loss: 0.0065 - val_mae: 0.0627\n",
            "Epoch 15/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 378ms/step - loss: 0.0033 - mae: 0.0372 - val_loss: 0.0042 - val_mae: 0.0479\n",
            "Epoch 16/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - loss: 0.0031 - mae: 0.0371 - val_loss: 0.0065 - val_mae: 0.0648\n",
            "Epoch 17/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 343ms/step - loss: 0.0029 - mae: 0.0367 - val_loss: 0.0041 - val_mae: 0.0499\n",
            "Epoch 18/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - loss: 0.0026 - mae: 0.0344 - val_loss: 0.0054 - val_mae: 0.0595\n",
            "Epoch 19/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 249ms/step - loss: 0.0024 - mae: 0.0328 - val_loss: 0.0037 - val_mae: 0.0482\n",
            "Epoch 20/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 313ms/step - loss: 0.0025 - mae: 0.0346 - val_loss: 0.0037 - val_mae: 0.0501\n",
            "Epoch 21/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 247ms/step - loss: 0.0024 - mae: 0.0347 - val_loss: 0.0041 - val_mae: 0.0516\n",
            "Epoch 22/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0044 - val_mae: 0.0535\n",
            "Epoch 23/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 247ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0042 - val_mae: 0.0526\n",
            "Epoch 24/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0071 - val_mae: 0.0679\n",
            "Epoch 25/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 250ms/step - loss: 0.0025 - mae: 0.0368 - val_loss: 0.0020 - val_mae: 0.0342\n",
            "Epoch 26/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 224ms/step - loss: 0.0024 - mae: 0.0354 - val_loss: 0.0033 - val_mae: 0.0460\n",
            "Epoch 27/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 288ms/step - loss: 0.0018 - mae: 0.0301 - val_loss: 0.0047 - val_mae: 0.0541\n",
            "Epoch 28/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 236ms/step - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0033 - val_mae: 0.0477\n",
            "Epoch 29/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 331ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0028 - val_mae: 0.0427\n",
            "Epoch 30/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 243ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0025 - val_mae: 0.0428\n",
            "Epoch 31/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 234ms/step - loss: 0.0020 - mae: 0.0334 - val_loss: 0.0034 - val_mae: 0.0503\n",
            "Epoch 32/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0053 - val_mae: 0.0597\n",
            "Epoch 33/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 0.0025 - val_mae: 0.0408\n",
            "Epoch 34/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0029 - val_mae: 0.0441\n",
            "Epoch 35/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 0.0034 - val_mae: 0.0470\n",
            "Epoch 36/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 381ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0028 - val_mae: 0.0435\n",
            "Epoch 37/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 225ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 0.0029 - val_mae: 0.0452\n",
            "Epoch 38/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 349ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0035 - val_mae: 0.0484\n",
            "Epoch 39/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0038 - val_mae: 0.0492\n",
            "Epoch 40/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 234ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0020 - val_mae: 0.0356\n",
            "Epoch 41/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 296ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0032 - val_mae: 0.0469\n",
            "Epoch 42/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 232ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 0.0041 - val_mae: 0.0504\n",
            "Epoch 43/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 287ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0049 - val_mae: 0.0565\n",
            "Epoch 44/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0044 - val_mae: 0.0537\n",
            "Epoch 45/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0037 - val_mae: 0.0479\n",
            "Epoch 46/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 405ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0040 - val_mae: 0.0511\n",
            "Epoch 47/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0025 - val_mae: 0.0393\n",
            "Epoch 48/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 242ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0039 - val_mae: 0.0512\n",
            "Epoch 49/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 343ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0019 - val_mae: 0.0357\n",
            "Epoch 50/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 239ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 0.0034 - val_mae: 0.0475\n",
            "\n",
            "--- Đánh giá Model trên tập Test ---\n",
            "Test Loss (MSE): 0.004639205988496542\n",
            "Test Mean Absolute Error (MAE): 0.05682598426938057\n"
          ]
        }
      ],
      "source": [
        "if X_np.shape[0] > 0 and model is not None:\n",
        "    # Huấn luyện model (có thể mất nhiều thời gian)\n",
        "    epochs = 50 # Số lần lặp qua toàn bộ tập huấn luyện\n",
        "    batch_size = 32 # Số mẫu được đưa vào model trong một lần cập nhật trọng số\n",
        "\n",
        "    print(\"\\n--- Bắt đầu huấn luyện Model ---\")\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    print(\"\\n--- Đánh giá Model trên tập Test ---\")\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Test Loss (MSE): {test_loss}\")\n",
        "    print(f\"Test Mean Absolute Error (MAE): {test_mae}\")\n",
        "\n",
        "    # Để lấy lại giá trị dự đoán về thang đo gốc, bạn cần dùng scaler_temp.inverse_transform() và scaler_hum.inverse_transform()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBMs21IvtQb4",
        "outputId": "612e239f-d9d5-41fa-eb7d-2ad68b3bcc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\n",
            "--- Dự đoán Nhiệt độ (24 giờ tới, mỗi 15 phút, thang đo gốc) ---\n",
            "[30.666487 30.88613  30.810629 30.85708  30.873081 30.825054 30.781733\n",
            " 30.746166 30.710384 30.67321  30.633812 30.594625 30.557749 30.523916\n",
            " 30.49354  30.466898 30.44735  30.442575 30.45196  30.473564 30.506716\n",
            " 30.552536 30.607676 30.670061 30.73809  30.80997  30.88314  30.9571\n",
            " 31.031769 31.107014 31.182625 31.258339 31.333836 31.408775 31.482794\n",
            " 31.55553  31.626371 31.693794 31.760832 31.82725  31.892311 31.95528\n",
            " 32.015507 32.072464 32.125748 32.175056 32.22019  32.26101  32.29746\n",
            " 32.329525 32.357235 32.380653 32.399887 32.41505  32.426292 32.433784\n",
            " 32.437702 32.43825  32.43551  32.42813  32.416313 32.4007   32.381832\n",
            " 32.360718 32.339775 32.319313 32.299213 32.279068 32.258488 32.23716\n",
            " 32.214863 32.19148  32.16695  32.14132  32.114647 32.08666  32.055935\n",
            " 32.022324 31.986858 31.950506 31.913681 31.87677  31.84007  31.803835\n",
            " 31.76811  31.732662 31.699139 31.667852 31.638783 31.611818 31.586824\n",
            " 31.56368  31.542307 31.522636 31.50465  31.488327]\n",
            "\n",
            "--- Dự đoán Độ ẩm (24 giờ tới, mỗi 15 phút, thang đo gốc) ---\n",
            "[69.11886  69.54416  69.55399  69.83202  69.98815  69.998245 70.12556\n",
            " 70.23778  70.32501  70.41134  70.50946  70.65339  70.849304 71.08142\n",
            " 71.33457  71.59525  71.82356  71.9654   71.992386 71.89748  71.70041\n",
            " 71.397064 70.99938  70.526405 69.99584  69.43145  68.86754  68.31078\n",
            " 67.768814 67.24832  66.75487  66.292915 65.86588  65.47624  65.12562\n",
            " 64.81489  64.549515 64.361565 64.23716  64.161835 64.12469  64.11792\n",
            " 64.13594  64.1747   64.23124  64.3033   64.389046 64.48692  64.595505\n",
            " 64.71346  64.839516 64.972404 65.1109   65.253815 65.39999  65.54833\n",
            " 65.69779  65.84741  65.99776  66.16756  66.35158  66.54635  66.74883\n",
            " 66.961716 67.20062  67.455055 67.7159   67.975945 68.22997  68.47431\n",
            " 68.70642  68.9247   69.12816  69.316345 69.48915  69.63808  69.73249\n",
            " 69.77819  69.79118  69.78189  69.759575 69.7309   69.700714 69.672455\n",
            " 69.651886 69.6554   69.68274  69.730545 69.79434  69.86958  69.95217\n",
            " 70.03849  70.125565 70.21092  70.292595 70.36905 ]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## Bước 11: (Placeholder) Dự đoán và Chuyển đổi ngược\n",
        "\n",
        "# Sau khi huấn luyện, bạn có thể dùng `model.predict()` và sau đó `scaler.inverse_transform()` để xem kết quả ở thang đo gốc.\n",
        "\n",
        "# ```python\n",
        "# Lấy một mẫu từ tập test để dự đoán\n",
        "sample_x = X_test[0:1] # Lấy mẫu đầu tiên, giữ nguyên dạng 3D\n",
        "predicted_scaled = model.predict(sample_x)\n",
        "\n",
        "predicted_temp_scaled = predicted_scaled[:, :, 0] # Lấy cột nhiệt độ đã chuẩn hóa\n",
        "predicted_hum_scaled = predicted_scaled[:, :, 1]  # Lấy cột độ ẩm đã chuẩn hóa\n",
        "\n",
        "# Chuyển đổi ngược về thang đo gốc\n",
        "predicted_temp_original = scaler_temp.inverse_transform(predicted_temp_scaled.reshape(-1,1)) # Reshape cho scaler\n",
        "predicted_hum_original = scaler_hum.inverse_transform(predicted_hum_scaled.reshape(-1,1))\n",
        "\n",
        "print(\"\\n--- Dự đoán Nhiệt độ (24 giờ tới, mỗi 15 phút, thang đo gốc) ---\")\n",
        "print(predicted_temp_original.flatten())\n",
        "print(\"\\n--- Dự đoán Độ ẩm (24 giờ tới, mỗi 15 phút, thang đo gốc) ---\")\n",
        "print(predicted_hum_original.flatten())\n",
        "# ```\n",
        "# ---\n",
        "# Kết thúc hướng dẫn chuẩn bị dữ liệu và khung sườn cho mô hình.\n",
        "# Bạn cần chạy các ô code theo thứ tự.\n",
        "# Hãy chú ý các phần **CẬP NHẬT** để đảm bảo mã phù hợp với dữ liệu của bạn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INF68IfQx2J6"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Bước 12: Lưu Model đã Huấn luyện\n",
        "#\n",
        "# Sau khi mô hình đã được huấn luyện, chúng ta sẽ lưu nó lại để có thể\n",
        "# sử dụng sau này mà không cần huấn luyện lại từ đầu.\n",
        "# Model sẽ được lưu dưới định dạng HDF5 (file .h5 hoặc .keras)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtFzOwKKx3PR",
        "outputId": "a5f9326e-46bf-42f1-f2fa-2eb127257bee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Đã lưu model thành công vào (HDF5): /content/drive/MyDrive/IOT_saved_model/nhiet_do_do_am_predictor.h5\n",
            "File này bao gồm kiến trúc model, trọng số và trạng thái optimizer.\n",
            "\n",
            "LƯU Ý: Nếu bạn sử dụng Keras 3 và muốn sử dụng định dạng .keras mới,\n",
            "bạn có thể thay đổi đuôi file thành '.keras', ví dụ: 'my_model.keras'.\n",
            "model.save('path/to/your_model.keras')\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "import os\n",
        "# Đảm bảo rằng tensorflow đã được import nếu bạn tách cell này ra xa\n",
        "# import tensorflow as tf\n",
        "\n",
        "if 'model' in locals() and model is not None:\n",
        "    # Tạo thư mục để lưu model nếu chưa có\n",
        "    output_model_dir = \"/content/drive/MyDrive/IOT_saved_model\"\n",
        "    if not os.path.exists(output_model_dir):\n",
        "        os.makedirs(output_model_dir)\n",
        "        print(f\"\\nĐã tạo thư mục: '{output_model_dir}'\")\n",
        "\n",
        "    # --- Lưu model dưới định dạng HDF5 (phổ biến) ---\n",
        "    model_path_h5 = os.path.join(output_model_dir, 'nhiet_do_do_am_predictor.h5')\n",
        "    try:\n",
        "        model.save(model_path_h5)\n",
        "        print(f\"\\nĐã lưu model thành công vào (HDF5): {model_path_h5}\")\n",
        "        print(\"File này bao gồm kiến trúc model, trọng số và trạng thái optimizer.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nLỖI khi lưu model dưới dạng HDF5: {e}\")\n",
        "        print(\"Hãy đảm bảo bạn đã cài đặt thư viện h5py: pip install h5py\")\n",
        "\n",
        "    # --- (Tùy chọn) Lưu model dưới định dạng SavedModel của TensorFlow ---\n",
        "    # Định dạng này là một thư mục, không phải một file đơn lẻ.\n",
        "    # model_path_tf = os.path.join(output_model_dir, 'nhiet_do_do_am_predictor_tf_format')\n",
        "    # try:\n",
        "    #     model.save(model_path_tf) # Không cần đuôi .h5 hay .keras\n",
        "    #     print(f\"\\nĐã lưu model thành công vào (TensorFlow SavedModel format): {model_path_tf}\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"\\nLỖI khi lưu model dưới dạng TensorFlow SavedModel: {e}\")\n",
        "\n",
        "    print(\"\\nLƯU Ý: Nếu bạn sử dụng Keras 3 và muốn sử dụng định dạng .keras mới,\")\n",
        "    print(\"bạn có thể thay đổi đuôi file thành '.keras', ví dụ: 'my_model.keras'.\")\n",
        "    print(\"model.save('path/to/your_model.keras')\")\n",
        "\n",
        "elif not ('model' in locals() and model is not None):\n",
        "    print(\"LỖI: Biến `model` không tồn tại hoặc chưa được huấn luyện.\")\n",
        "    print(\"Vui lòng đảm bảo bạn đã chạy các ô code định nghĩa và huấn luyện model trước khi lưu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RERiIksi2FVT",
        "outputId": "cc17fa9a-6edf-40d3-9e72-b033c77f2e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting paho-mqtt==1.6.1\n",
            "  Downloading paho-mqtt-1.6.1.tar.gz (99 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/99.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: paho-mqtt\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paho-mqtt: filename=paho_mqtt-1.6.1-py3-none-any.whl size=62116 sha256=ea7042045c98d0d70a2b207cda3f89f5c807a4fdb64ea4352d37885aefcdd42e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/ea/a5/ba9a63aaf4cd4e16e8a87ee31fb4d11b04ff5e1735d312619a\n",
            "Successfully built paho-mqtt\n",
            "Installing collected packages: paho-mqtt\n",
            "Successfully installed paho-mqtt-1.6.1\n"
          ]
        }
      ],
      "source": [
        "pip install paho-mqtt==1.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LEtGnUq1t1s",
        "outputId": "aacef6ba-77d8-44c9-a7fd-fd8450d006a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting schedule\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.2\n"
          ]
        }
      ],
      "source": [
        "pip install schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMwvtkB1zO1B",
        "outputId": "44ec2445-1777-41e1-c254-8f7ef390fbc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "rx9Teu8e7OoW",
        "outputId": "56543bef-2e35-4ec5-c15c-4ee70ee812f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Advanced IoT Application with Full Prediction Reporting...\n",
            "Starting Main Application...\n",
            "Data for testing will be sourced from: /content/drive/MyDrive/dataset/datacsv.csv\n",
            "\n",
            "Inspecting columns in '/content/drive/MyDrive/dataset/datacsv.csv'...\n",
            "Columns found in CSV: ['ID', 'Timestamp', 'humidity', 'temperature']\n",
            "First 5 rows of the CSV:\n",
            "   ID            Timestamp   humidity  temperature\n",
            "0   1  2025-05-14 16:18:56  56.568050    27.420235\n",
            "1   2  2025-05-14 16:19:06  57.285023    27.423477\n",
            "2   3  2025-05-14 16:19:16  57.293415    27.423668\n",
            "3   4  2025-05-14 16:19:26  57.070732    27.427673\n",
            "4   5  2025-05-14 16:21:03  57.070732    27.427673\n",
            "\n",
            "IMPORTANT: Script currently assumes temperature column is 'temperature' and humidity column is 'humidity'.\n",
            "Please VERIFY these names from the 'Columns found in CSV' output above.\n",
            "If they are different, UPDATE the 'assumed_temp_col' and 'assumed_humi_col' variables at the beginning of the 'if __name__ == \"__main__\":' block.\n",
            "Model '/content/drive/MyDrive/IOT_saved_model/nhiet_do_do_am_predictor.h5' loaded successfully.\n",
            "\n",
            "Fitting scalers using data from '/content/drive/MyDrive/dataset/datacsv.csv' (Placeholder - use pre-fitted scalers from training data).\n",
            "Scalers fitted for this session using columns: 'temperature' and 'humidity'.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'username_pw_set'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-571c49326a53>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;31m# mqtt_client = mqttclient.Client(client_id=\"FullPredictDevice_01\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;31m# mqtt_client = mqttclient.Client(\"Sensor C1\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mmqtt_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musername_pw_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mACCESS_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m     \u001b[0mmqtt_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_connect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mon_connect_mqtt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0mmqtt_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_disconnect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mon_disconnect_mqtt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'username_pw_set'"
          ]
        }
      ],
      "source": [
        "import paho.mqtt.client as mqttclient\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta # Thêm timedelta\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import MeanSquaredError # Hoặc tf.keras.metrics.MeanSquaredError nếu dùng làm metric\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import collections\n",
        "import schedule\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "import threading\n",
        "import os # Để tạo thư mục\n",
        "# import joblib # Bỏ comment nếu bạn dùng joblib để lưu/tải scalers\n",
        "\n",
        "print(\"Initializing Advanced IoT Application with Full Prediction Reporting...\")\n",
        "\n",
        "# --- Configuration Constants ---\n",
        "# MQTT Configuration\n",
        "BROKER_ADDRESS = \"app.coreiot.io\"\n",
        "PORT = 1883\n",
        "ACCESS_TOKEN = \"kNT0dUABeA28fk7jFbpe\"\n",
        "\n",
        "# Model and Data Parameters\n",
        "N_STEPS_IN = 12\n",
        "N_FEATURES = 2\n",
        "N_STEPS_OUT = 96\n",
        "DATA_SAMPLING_INTERVAL_SECONDS = 1\n",
        "\n",
        "# Scheduling Configuration\n",
        "PREDICTION_INTERVAL_MINUTES = 2\n",
        "\n",
        "# Email Configuration (CẦN THAY THẾ BẰNG THÔNG TIN CỦA BẠN)\n",
        "SMTP_SERVER = 'smtp.gmail.com'  # Ví dụ cho Gmail\n",
        "SMTP_PORT = 587  # Hoặc 465 cho SSL\n",
        "EMAIL_SENDER = 'tuan.tranhoangkhoii@hcmut.edu.vn' # Email của bạn\n",
        "EMAIL_PASSWORD = 'guhy rafi hcqw eequ'    # Mật khẩu ứng dụng cho email của bạn\n",
        "EMAIL_RECIPIENT = 'khoituan65@gmail.com' # Email người nhận\n",
        "\n",
        "# Alarm Thresholds (CẦN ĐIỀU CHỈNH)\n",
        "TEMP_ALARM_THRESHOLD = 32.0\n",
        "HUMI_ALARM_THRESHOLD = 75.0\n",
        "\n",
        "# --- Global Variables ---\n",
        "data_buffer = collections.deque(maxlen=(2 * 60 // DATA_SAMPLING_INTERVAL_SECONDS) + 20)\n",
        "latest_actual_temp = None\n",
        "latest_actual_humi = None\n",
        "latest_predictions_temp_full = None\n",
        "latest_predictions_humi_full = None\n",
        "model = None\n",
        "scaler_temp = None\n",
        "scaler_humi = None\n",
        "mqtt_client = None\n",
        "\n",
        "# --- MQTT Callbacks ---\n",
        "def on_connect_mqtt(client, userdata, flags, rc):\n",
        "    if rc == 0:\n",
        "        print(f\"MQTT: Connected successfully to {BROKER_ADDRESS}!\")\n",
        "    else:\n",
        "        print(f\"MQTT: Connection failed to {BROKER_ADDRESS}, result code {rc}\")\n",
        "\n",
        "def on_disconnect_mqtt(client, userdata, rc):\n",
        "    print(f\"MQTT: Disconnected from {BROKER_ADDRESS} with result code {rc}.\")\n",
        "\n",
        "def on_publish_mqtt(client, userdata, mid):\n",
        "    print(f\"MQTT: Data published successfully, mid: {mid}\")\n",
        "\n",
        "# --- Email Sending Function ---\n",
        "def send_email_generic(subject, body_html, recipient=EMAIL_RECIPIENT, sender=EMAIL_SENDER, password=EMAIL_PASSWORD):\n",
        "    try:\n",
        "        msg = MIMEMultipart('alternative')\n",
        "        msg['From'] = sender\n",
        "        msg['To'] = recipient\n",
        "        msg['Subject'] = subject\n",
        "        msg.attach(MIMEText(body_html, 'html'))\n",
        "\n",
        "        server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n",
        "        server.starttls()\n",
        "        server.login(sender, password)\n",
        "        text = msg.as_string()\n",
        "        server.sendmail(sender, recipient, text)\n",
        "        server.quit()\n",
        "        print(f\"Email sent successfully to {recipient} with subject: {subject}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error sending email: {e}\")\n",
        "        return False\n",
        "\n",
        "# --- Function to Email FULL Predictions (Cập nhật thời gian tuyệt đối) ---\n",
        "def send_full_prediction_email(predicted_temps_full, predicted_humis_full, prediction_start_time): # Thêm prediction_start_time\n",
        "    global latest_actual_temp, latest_actual_humi\n",
        "    subject = f\"Full 24-Hour Weather Prediction Report - {prediction_start_time.strftime('%Y-%m-%d %H:%M')}\"\n",
        "\n",
        "    body_html = f\"<html><body><h2>Full 24-Hour Weather Prediction Report</h2>\"\n",
        "    body_html += f\"<p>Prediction generated at: <strong>{prediction_start_time.strftime('%Y-%m-%d %H:%M:%S')}</strong></p>\"\n",
        "\n",
        "    if latest_actual_temp is not None and latest_actual_humi is not None:\n",
        "        body_html += f\"<h3>Latest Actual Readings (around prediction time):</h3>\"\n",
        "        body_html += f\"<p>Temperature: {latest_actual_temp:.2f}°C</p>\"\n",
        "        body_html += f\"<p>Humidity: {latest_actual_humi:.2f}%</p><hr>\"\n",
        "\n",
        "    body_html += \"<h3>Predicted Values (Next 24 Hours):</h3>\"\n",
        "    body_html += \"<table border='1' style='border-collapse: collapse; width:70%;'>\" # Tăng chiều rộng bảng\n",
        "    body_html += \"<tr><th>Predicted Time (Actual)</th><th>Temperature (°C)</th><th>Humidity (%)</th></tr>\"\n",
        "\n",
        "    for i in range(len(predicted_temps_full)):\n",
        "        # Tính toán thời gian tuyệt đối cho mỗi điểm dự đoán\n",
        "        time_offset_minutes = (i + 1) * 15 # Mỗi điểm dự đoán cách nhau 15 phút\n",
        "        absolute_prediction_time = prediction_start_time + timedelta(minutes=time_offset_minutes)\n",
        "        time_label_absolute = absolute_prediction_time.strftime(\"%Y-%m-%d %H:%M\") # Định dạng ngày giờ phút\n",
        "\n",
        "        temp = predicted_temps_full[i]\n",
        "        humi = predicted_humis_full[i]\n",
        "        body_html += f\"<tr><td style='text-align:center;'>{time_label_absolute}</td><td style='text-align:center;'>{temp:.2f}</td><td style='text-align:center;'>{humi:.2f}</td></tr>\"\n",
        "\n",
        "    body_html += \"</table></body></html>\"\n",
        "    send_email_generic(subject, body_html)\n",
        "\n",
        "# --- Function to Check and Send Alarm Email (Cập nhật thời gian tuyệt đối) ---\n",
        "def check_and_send_alarm_email(predicted_temps_full, predicted_humis_full, temp_thresh, humi_thresh, prediction_start_time): # Thêm prediction_start_time\n",
        "    global latest_actual_temp, latest_actual_humi\n",
        "    alarm_triggers = []\n",
        "\n",
        "    for i in range(len(predicted_temps_full)):\n",
        "        # Tính toán thời gian tuyệt đối cho điểm dự đoán này\n",
        "        time_offset_minutes = (i + 1) * 15\n",
        "        absolute_alarm_time = prediction_start_time + timedelta(minutes=time_offset_minutes)\n",
        "        time_label_absolute = absolute_alarm_time.strftime(\"%Y-%m-%d %H:%M\") # Định dạng ngày giờ phút\n",
        "\n",
        "        if predicted_temps_full[i] > temp_thresh:\n",
        "            alarm_triggers.append(\n",
        "                f\"Nhiệt độ dự đoán CAO: {predicted_temps_full[i]:.2f}°C (Ngưỡng: {temp_thresh}°C) vào lúc {time_label_absolute}\"\n",
        "            )\n",
        "\n",
        "        if predicted_humis_full[i] > humi_thresh:\n",
        "            alarm_triggers.append(\n",
        "                f\"Độ ẩm dự đoán CAO: {predicted_humis_full[i]:.2f}% (Ngưỡng: {humi_thresh}%) vào lúc {time_label_absolute}\"\n",
        "            )\n",
        "\n",
        "    if alarm_triggers:\n",
        "        subject = f\"🚨 CẢNH BÁO THỜI TIẾT KHẨN CẤP! - {prediction_start_time.strftime('%Y-%m-%d %H:%M')} 🚨\"\n",
        "        body_html = f\"<html><body><h2>Weather Alarm Details (Prediction from {prediction_start_time.strftime('%Y-%m-%d %H:%M:%S')}):</h2>\"\n",
        "        body_html += \"<ul>\"\n",
        "        for trigger in alarm_triggers:\n",
        "            body_html += f\"<li>{trigger}</li>\"\n",
        "        body_html += \"</ul><hr>\"\n",
        "\n",
        "        if latest_actual_temp is not None and latest_actual_humi is not None:\n",
        "            body_html += f\"<p><strong>Current Actual Temperature (around prediction time):</strong> {latest_actual_temp:.2f}°C</p>\"\n",
        "            body_html += f\"<p><strong>Current Actual Humidity (around prediction time):</strong> {latest_actual_humi:.2f}%</p>\"\n",
        "\n",
        "        body_html += \"<h3>Summary of Full Prediction Period:</h3>\"\n",
        "        body_html += f\"<p>Max Predicted Temperature: {np.max(predicted_temps_full):.2f}°C</p>\"\n",
        "        # ... (các dòng tóm tắt khác giữ nguyên) ...\n",
        "        body_html += f\"<p>Min Predicted Humidity: {np.min(predicted_humis_full):.2f}%</p>\"\n",
        "        body_html += \"</body></html>\"\n",
        "\n",
        "        send_email_generic(subject, body_html)\n",
        "        print(f\"ALARM EMAIL SENT due to: {', '.join(alarm_triggers)}\")\n",
        "    else:\n",
        "        print(f\"No alarm conditions met for predicted values from {prediction_start_time.strftime('%Y-%m-%d %H:%M:%S')}.\")\n",
        "\n",
        "# --- Scheduled Prediction Function ---\n",
        "def run_prediction_cycle():\n",
        "    global latest_predictions_temp_full, latest_predictions_humi_full, model\n",
        "    global scaler_temp, scaler_humi, latest_actual_temp, latest_actual_humi, mqtt_client\n",
        "\n",
        "    # --- GHI LẠI THỜI ĐIỂM BẮT ĐẦU DỰ ĐOÁN ---\n",
        "    prediction_initiation_time = datetime.now()\n",
        "    current_time_str_display = prediction_initiation_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"\\n--- Running scheduled prediction cycle at {current_time_str_display} ---\")\n",
        "\n",
        "    if model is None or scaler_temp is None or scaler_humi is None:\n",
        "        print(\"Model or scalers not loaded. Skipping prediction.\")\n",
        "        return\n",
        "\n",
        "    if len(data_buffer) < N_STEPS_IN:\n",
        "        print(f\"Not enough data in buffer ({len(data_buffer)} points) for prediction. Need {N_STEPS_IN}.\")\n",
        "        return\n",
        "\n",
        "    current_data_sequence = list(data_buffer)[-N_STEPS_IN:]\n",
        "    humi_seq_raw = np.array([item[1] for item in current_data_sequence])\n",
        "    temp_seq_raw = np.array([item[2] for item in current_data_sequence])\n",
        "\n",
        "    latest_actual_humi = float(humi_seq_raw[-1])\n",
        "    latest_actual_temp = float(temp_seq_raw[-1])\n",
        "\n",
        "    humi_seq_scaled = scaler_humi.transform(humi_seq_raw.reshape(-1, 1)).flatten()\n",
        "    temp_seq_scaled = scaler_temp.transform(temp_seq_raw.reshape(-1, 1)).flatten()\n",
        "\n",
        "    x_input_scaled = np.vstack((humi_seq_scaled, temp_seq_scaled)).T\n",
        "    x_input_scaled = x_input_scaled.reshape((1, N_STEPS_IN, N_FEATURES))\n",
        "\n",
        "    predicted_values_scaled = model.predict(x_input_scaled, verbose=0)\n",
        "\n",
        "    humi_predictions_scaled = predicted_values_scaled[0, :, 0].reshape(-1, 1)\n",
        "    temp_predictions_scaled = predicted_values_scaled[0, :, 1].reshape(-1, 1)\n",
        "\n",
        "    latest_predictions_humi_full = scaler_humi.inverse_transform(humi_predictions_scaled).flatten()\n",
        "    latest_predictions_temp_full = scaler_temp.inverse_transform(temp_predictions_scaled).flatten()\n",
        "\n",
        "    print(f\"Prediction successful. First predicted Temp (T+15min from {current_time_str_display}): {latest_predictions_temp_full[0]:.2f}°C, Humi: {latest_predictions_humi_full[0]:.2f}%\")\n",
        "\n",
        "    # # ... (Phần publish MQTT giữ nguyên) ...\n",
        "    # if mqtt_client and mqtt_client.is_connected():\n",
        "    #     payload_coreiot = {\n",
        "    #         'timestamp_prediction_event': prediction_initiation_time.timestamp(), # Gửi timestamp dạng số\n",
        "    #         'temperature_actual': latest_actual_temp,\n",
        "    #         'humidity_actual': latest_actual_humi,\n",
        "    #         'predicted_temperatures_24h': [round(float(t), 2) for t in latest_predictions_temp_full],\n",
        "    #         'predicted_humidities_24h': [round(float(h), 2) for h in latest_predictions_humi_full],\n",
        "    #     }\n",
        "    #     try:\n",
        "    #         mqtt_client.publish('v1/devices/me/telemetry', json.dumps(payload_coreiot), 1)\n",
        "    #         print(\"MQTT: Published FULL PREDICTIONS to CoreIOT.\")\n",
        "    #     except Exception as e_mqtt:\n",
        "    #         print(f\"MQTT Error publishing full predictions: {e_mqtt}\")\n",
        "    # # ...\n",
        "\n",
        "\n",
        "    # 1. Send FULL predictions to CoreIOT Server\n",
        "    if mqtt_client and mqtt_client.is_connected():\n",
        "        payload_coreiot = {\n",
        "            'timestamp': time.time(), # Add a timestamp for the prediction event\n",
        "            'temperature_actual': latest_actual_temp,\n",
        "            'humidity_actual': latest_actual_humi,\n",
        "            'predicted_temperatures_24h': [round(float(t), 2) for t in latest_predictions_temp_full],\n",
        "            'predicted_humidities_24h': [round(float(h), 2) for h in latest_predictions_humi_full],\n",
        "            # Add other relevant actual data if available (light, GPS, etc.)\n",
        "        }\n",
        "        try:\n",
        "            mqtt_client.publish('v1/devices/me/telemetry', json.dumps(payload_coreiot), 1)\n",
        "            # on_publish_mqtt callback will confirm, or can print here\n",
        "        except Exception as e_mqtt:\n",
        "            print(f\"MQTT Error publishing full predictions: {e_mqtt}\")\n",
        "    elif mqtt_client:\n",
        "        print(\"MQTT client not connected. Cannot send full predictions to CoreIOT.\")\n",
        "    else:\n",
        "        print(\"MQTT client not initialized. Cannot send full predictions to CoreIOT.\")\n",
        "\n",
        "    # --- TRUYỀN prediction_initiation_time VÀO HÀM EMAIL ---\n",
        "    send_full_prediction_email(latest_predictions_temp_full, latest_predictions_humi_full, prediction_initiation_time)\n",
        "    check_and_send_alarm_email(latest_predictions_temp_full, latest_predictions_humi_full,\n",
        "                               TEMP_ALARM_THRESHOLD, HUMI_ALARM_THRESHOLD, prediction_initiation_time)\n",
        "\n",
        "# --- Function to Simulate Sensor Data and Populate Buffer (from CSV) ---\n",
        "# <--- THAY ĐỔI / LƯU Ý QUAN TRỌNG: Thêm tham số tên cột\n",
        "def populate_data_buffer_from_csv(csv_path, temp_col_name_in_csv, humi_col_name_in_csv):\n",
        "    global data_buffer\n",
        "    print(f\"Data Populator: Attempting to load data from CSV: {csv_path}\")\n",
        "    try:\n",
        "        data_df = pd.read_csv(csv_path)\n",
        "        # --- SỬ DỤNG TÊN CỘT ĐƯỢC TRUYỀN VÀO ---\n",
        "        if humi_col_name_in_csv not in data_df.columns or temp_col_name_in_csv not in data_df.columns:\n",
        "            print(f\"Data Populator CSV Error: Required columns ('{humi_col_name_in_csv}', '{temp_col_name_in_csv}') not found in CSV.\")\n",
        "            return\n",
        "\n",
        "        humidity_all_raw = data_df[humi_col_name_in_csv].values.astype(float)\n",
        "        temperature_all_raw = data_df[temp_col_name_in_csv].values.astype(float)\n",
        "\n",
        "        if scaler_humi is None or scaler_temp is None: # Kiểm tra lại\n",
        "             print(\"Data Populator Warning: Scalers not initialized when populator started.\")\n",
        "\n",
        "        idx = 0\n",
        "        while True:\n",
        "            if idx >= len(temperature_all_raw):\n",
        "                print(\"Data Populator: Reached end of CSV. Looping again.\")\n",
        "                idx = 0\n",
        "\n",
        "            current_humi = humidity_all_raw[idx]\n",
        "            current_temp = temperature_all_raw[idx]\n",
        "            current_timestamp = time.time()\n",
        "\n",
        "            data_buffer.append((current_timestamp, current_humi, current_temp))\n",
        "            idx += 1\n",
        "            time.sleep(DATA_SAMPLING_INTERVAL_SECONDS)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Data Populator FATAL: CSV file not found at '{csv_path}'\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Data Populator FATAL: KeyError - likely a wrong column name ('{temp_col_name_in_csv}' or '{humi_col_name_in_csv}') not found in CSV. Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Data Populator FATAL: Error in data population thread: {e}\")\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Main Application...\")\n",
        "\n",
        "    model_path = '/content/drive/MyDrive/IOT_saved_model/nhiet_do_do_am_predictor.h5'\n",
        "    # --- THAY ĐỔI / LƯU Ý QUAN TRỌNG: Sử dụng file datacsv.csv ---\n",
        "    csv_data_path = '/content/drive/MyDrive/dataset/datacsv.csv'\n",
        "    print(f\"Data for testing will be sourced from: {csv_data_path}\")\n",
        "\n",
        "    # --- USER MUST VERIFY AND UPDATE ---\n",
        "    # Các biến này sẽ lưu trữ tên cột thực tế sau khi bạn kiểm tra file CSV\n",
        "    assumed_temp_col = 'temperature' # THAY THẾ NẾU CẦN\n",
        "    assumed_humi_col = 'humidity'  # THAY THẾ NẾU CẦN\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nInspecting columns in '{csv_data_path}'...\")\n",
        "        temp_inspection_df = pd.read_csv(csv_data_path)\n",
        "        actual_columns = temp_inspection_df.columns.tolist()\n",
        "        print(\"Columns found in CSV:\", actual_columns)\n",
        "        print(\"First 5 rows of the CSV:\")\n",
        "        print(temp_inspection_df.head().to_string())\n",
        "\n",
        "        print(f\"\\nIMPORTANT: Script currently assumes temperature column is '{assumed_temp_col}' and humidity column is '{assumed_humi_col}'.\")\n",
        "        print(\"Please VERIFY these names from the 'Columns found in CSV' output above.\")\n",
        "        print(\"If they are different, UPDATE the 'assumed_temp_col' and 'assumed_humi_col' variables at the beginning of the 'if __name__ == \\\"__main__\\\":' block.\")\n",
        "\n",
        "        if assumed_temp_col not in actual_columns or assumed_humi_col not in actual_columns:\n",
        "            print(f\"\\nWARNING: One or both assumed columns ('{assumed_temp_col}', '{assumed_humi_col}') were NOT FOUND in '{csv_data_path}'.\")\n",
        "            print(\"Please correct the 'assumed_temp_col' and 'assumed_humi_col' variables in the script before proceeding seriously.\")\n",
        "            # Forcing user to acknowledge, or script might fail later\n",
        "            # corrected_temp_col = input(f\"Enter correct temperature column name (or press Enter to use '{assumed_temp_col}'): \")\n",
        "            # corrected_humi_col = input(f\"Enter correct humidity column name (or press Enter to use '{assumed_humi_col}'): \")\n",
        "            # if corrected_temp_col: assumed_temp_col = corrected_temp_col\n",
        "            # if corrected_humi_col: assumed_humi_col = corrected_humi_col\n",
        "            # print(f\"Using Temperature Column: '{assumed_temp_col}', Humidity Column: '{assumed_humi_col}'\")\n",
        "\n",
        "        del temp_inspection_df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"FATAL: Test data CSV file not found at '{csv_data_path}'.\")\n",
        "        exit()\n",
        "    except Exception as e:\n",
        "        print(f\"FATAL: Error reading or inspecting CSV file '{csv_data_path}': {e}\")\n",
        "        exit()\n",
        "\n",
        "    # scaler_dir = \"scalers\" # Bỏ comment nếu bạn dùng joblib để lưu scalers\n",
        "    # if not os.path.exists(scaler_dir):\n",
        "    #     os.makedirs(scaler_dir)\n",
        "    # scaler_temp_path = os.path.join(scaler_dir, \"scaler_temp.joblib\")\n",
        "    # scaler_humi_path = os.path.join(scaler_dir, \"scaler_humi.joblib\")\n",
        "\n",
        "    try:\n",
        "        model = load_model(model_path, custom_objects={'mse': MeanSquaredError()})\n",
        "        print(f\"Model '{model_path}' loaded successfully.\")\n",
        "\n",
        "        print(f\"\\nFitting scalers using data from '{csv_data_path}' (Placeholder - use pre-fitted scalers from training data).\")\n",
        "        df_for_scaler_fitting = pd.read_csv(csv_data_path)\n",
        "\n",
        "        if assumed_temp_col not in df_for_scaler_fitting.columns:\n",
        "            print(f\"FATAL: Confirmed temperature column '{assumed_temp_col}' NOT FOUND in CSV for scaler fitting.\")\n",
        "            exit()\n",
        "        if assumed_humi_col not in df_for_scaler_fitting.columns:\n",
        "            print(f\"FATAL: Confirmed humidity column '{assumed_humi_col}' NOT FOUND in CSV for scaler fitting.\")\n",
        "            exit()\n",
        "\n",
        "        scaler_temp = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaler_humi = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "        scaler_temp.fit(df_for_scaler_fitting[[assumed_temp_col]].astype(float))\n",
        "        scaler_humi.fit(df_for_scaler_fitting[[assumed_humi_col]].astype(float))\n",
        "        print(f\"Scalers fitted for this session using columns: '{assumed_temp_col}' and '{assumed_humi_col}'.\")\n",
        "        del df_for_scaler_fitting\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"FATAL: CSV file '{csv_data_path}' not found during scaler fitting.\")\n",
        "        exit()\n",
        "    except KeyError as e:\n",
        "        print(f\"FATAL: KeyError during scaler fitting using assumed columns. Column not found: {e}.\")\n",
        "        exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during initial model/scaler setup: {e}\")\n",
        "        exit()\n",
        "\n",
        "    # mqtt_client = mqttclient.Client(client_id=\"4c72b3f0-0555-11f0-a887-6d1a184f2bb5\")\n",
        "    # mqtt_client = mqttclient.Client(client_id=\"FullPredictDevice_01\")\n",
        "    # mqtt_client = mqttclient.Client(\"Sensor C1\")\n",
        "    mqtt_client.username_pw_set(username=None, password=ACCESS_TOKEN)\n",
        "    mqtt_client.on_connect = on_connect_mqtt\n",
        "    mqtt_client.on_disconnect = on_disconnect_mqtt\n",
        "    mqtt_client.on_publish = on_publish_mqtt\n",
        "    try:\n",
        "        print(f\"Attempting to connect to MQTT broker: {BROKER_ADDRESS}:{PORT}\")\n",
        "        mqtt_client.connect(BROKER_ADDRESS, PORT, 60)\n",
        "        mqtt_client.loop_start()\n",
        "    except Exception as e_mqtt_main:\n",
        "        print(f\"Main MQTT Connection Error: {e_mqtt_main}\")\n",
        "\n",
        "    # --- THAY ĐỔI / LƯU Ý QUAN TRỌNG: Truyền tên cột đã xác nhận vào thread\n",
        "    data_populator_thread = threading.Thread(\n",
        "        target=populate_data_buffer_from_csv,\n",
        "        args=(csv_data_path, assumed_temp_col, assumed_humi_col), # Truyền tên cột\n",
        "        daemon=True\n",
        "    )\n",
        "    data_populator_thread.start()\n",
        "    print(\"Data population thread started.\")\n",
        "\n",
        "    print(f\"Waiting for initial data buffer to fill (approx. {DATA_SAMPLING_INTERVAL_SECONDS * (N_STEPS_IN + 3)} seconds)...\")\n",
        "    time.sleep(DATA_SAMPLING_INTERVAL_SECONDS * (N_STEPS_IN + 3))\n",
        "\n",
        "    print(f\"Scheduling prediction job to run every {PREDICTION_INTERVAL_MINUTES} minutes.\")\n",
        "    schedule.every(PREDICTION_INTERVAL_MINUTES).minutes.do(run_prediction_cycle)\n",
        "\n",
        "    if len(data_buffer) >= N_STEPS_IN:\n",
        "        print(\"Buffer has enough data. Running initial prediction cycle...\")\n",
        "        run_prediction_cycle()\n",
        "    else:\n",
        "        print(f\"Buffer has {len(data_buffer)}/{N_STEPS_IN} points. Not enough for initial prediction. Waiting for scheduled run.\")\n",
        "\n",
        "    print(\"Scheduler started. Press Ctrl+C to exit.\")\n",
        "    try:\n",
        "        while True:\n",
        "            schedule.run_pending()\n",
        "            time.sleep(1)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nApplication shutting down by user request...\")\n",
        "    finally:\n",
        "        if mqtt_client and mqtt_client.is_connected(): # Kiểm tra is_connected() trước khi ngắt\n",
        "            mqtt_client.loop_stop()\n",
        "            mqtt_client.disconnect()\n",
        "            print(\"MQTT client disconnected.\")\n",
        "        print(\"Scheduler stopped. Exiting.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
